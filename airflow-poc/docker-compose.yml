version: '3.8'

services:
  airflow-init:
    image: apache/airflow:2.7.3-python3.11
    networks:
      - intangles_default
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@${AIRFLOW_DB_HOST}:${AIRFLOW_DB_PORT}/${AIRFLOW_DB_NAME}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DEFAULT_TIMEZONE: 'Asia/Kolkata'
      AWS_PROFILE: ${AWS_PROFILE}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: 'admin'
      _AIRFLOW_WWW_USER_PASSWORD: 'admin'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config
      - ./requirements.txt:/requirements.txt
      - ~/.aws:/home/airflow/.aws:ro
    command: bash -c "pip install -r /requirements.txt && airflow db migrate && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"

  airflow-webserver:
    image: apache/airflow:2.7.3-python3.11
    depends_on:
      - airflow-init
    networks:
      - intangles_default
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@${AIRFLOW_DB_HOST}:${AIRFLOW_DB_PORT}/${AIRFLOW_DB_NAME}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DEFAULT_TIMEZONE: 'Asia/Kolkata'
      AWS_PROFILE: ${AWS_PROFILE}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      TIMESCALE_HOST: ${TIMESCALE_HOST}
      TIMESCALE_PORT: ${TIMESCALE_PORT}
      TIMESCALE_DB: ${TIMESCALE_DB}
      TIMESCALE_USER: ${TIMESCALE_USER}
      TIMESCALE_PASSWORD: ${TIMESCALE_PASSWORD}
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config
      - ./requirements.txt:/requirements.txt
      - ~/.aws:/home/airflow/.aws:ro
    command: bash -c "pip install -r /requirements.txt && airflow webserver"

  airflow-scheduler:
    image: apache/airflow:2.7.3-python3.11
    depends_on:
      - airflow-init
    networks:
      - intangles_default
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@${AIRFLOW_DB_HOST}:${AIRFLOW_DB_PORT}/${AIRFLOW_DB_NAME}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DEFAULT_TIMEZONE: 'Asia/Kolkata'
      AWS_PROFILE: ${AWS_PROFILE}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET}
      TIMESCALE_HOST: ${TIMESCALE_HOST}
      TIMESCALE_PORT: ${TIMESCALE_PORT}
      TIMESCALE_DB: ${TIMESCALE_DB}
      TIMESCALE_USER: ${TIMESCALE_USER}
      TIMESCALE_PASSWORD: ${TIMESCALE_PASSWORD}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./config:/opt/airflow/config
      - ./requirements.txt:/requirements.txt
      - ~/.aws:/home/airflow/.aws:ro
    command: bash -c "pip install -r /requirements.txt && airflow scheduler"

networks:
  intangles_default:
    external: true